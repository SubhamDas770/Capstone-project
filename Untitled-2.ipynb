{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling/Normalization: Standardize the dataset to ensure consistent data scales.\n",
    "Fill Missing Values: Handle missing data points appropriately.\n",
    "Feature Selection & Engineering: Identify and create relevant features for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id         target      ps_ind_01  ps_ind_02_cat  \\\n",
      "count  5.952120e+05  595212.000000  595212.000000  595212.000000   \n",
      "mean   7.438036e+05       0.036448       1.900378       1.358943   \n",
      "std    4.293678e+05       0.187401       1.983789       0.664594   \n",
      "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
      "25%    3.719915e+05       0.000000       0.000000       1.000000   \n",
      "50%    7.435475e+05       0.000000       1.000000       1.000000   \n",
      "75%    1.115549e+06       0.000000       3.000000       2.000000   \n",
      "max    1.488027e+06       1.000000       7.000000       4.000000   \n",
      "\n",
      "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
      "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
      "mean        4.423318       0.416794       0.405188       0.393742   \n",
      "std         2.699902       0.493311       1.350642       0.488579   \n",
      "min         0.000000      -1.000000      -1.000000       0.000000   \n",
      "25%         2.000000       0.000000       0.000000       0.000000   \n",
      "50%         4.000000       0.000000       0.000000       0.000000   \n",
      "75%         6.000000       1.000000       0.000000       1.000000   \n",
      "max        11.000000       1.000000       6.000000       1.000000   \n",
      "\n",
      "       ps_ind_07_bin  ps_ind_08_bin  ...     ps_calc_11     ps_calc_12  \\\n",
      "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
      "mean        0.257033       0.163921  ...       5.441382       1.441918   \n",
      "std         0.436998       0.370205  ...       2.332871       1.202963   \n",
      "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
      "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
      "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
      "75%         1.000000       0.000000  ...       7.000000       2.000000   \n",
      "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
      "\n",
      "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
      "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
      "mean        2.872288       7.539026        0.122427        0.627840   \n",
      "std         1.694887       2.746652        0.327779        0.483381   \n",
      "min         0.000000       0.000000        0.000000        0.000000   \n",
      "25%         2.000000       6.000000        0.000000        0.000000   \n",
      "50%         3.000000       7.000000        0.000000        1.000000   \n",
      "75%         4.000000       9.000000        0.000000        1.000000   \n",
      "max        13.000000      23.000000        1.000000        1.000000   \n",
      "\n",
      "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
      "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
      "mean         0.554182        0.287182        0.349024        0.153318  \n",
      "std          0.497056        0.452447        0.476662        0.360295  \n",
      "min          0.000000        0.000000        0.000000        0.000000  \n",
      "25%          0.000000        0.000000        0.000000        0.000000  \n",
      "50%          1.000000        0.000000        0.000000        0.000000  \n",
      "75%          1.000000        1.000000        1.000000        0.000000  \n",
      "max          1.000000        1.000000        1.000000        1.000000  \n",
      "\n",
      "[8 rows x 59 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595212 entries, 0 to 595211\n",
      "Data columns (total 59 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              595212 non-null  int64  \n",
      " 1   target          595212 non-null  int64  \n",
      " 2   ps_ind_01       595212 non-null  int64  \n",
      " 3   ps_ind_02_cat   595212 non-null  int64  \n",
      " 4   ps_ind_03       595212 non-null  int64  \n",
      " 5   ps_ind_04_cat   595212 non-null  int64  \n",
      " 6   ps_ind_05_cat   595212 non-null  int64  \n",
      " 7   ps_ind_06_bin   595212 non-null  int64  \n",
      " 8   ps_ind_07_bin   595212 non-null  int64  \n",
      " 9   ps_ind_08_bin   595212 non-null  int64  \n",
      " 10  ps_ind_09_bin   595212 non-null  int64  \n",
      " 11  ps_ind_10_bin   595212 non-null  int64  \n",
      " 12  ps_ind_11_bin   595212 non-null  int64  \n",
      " 13  ps_ind_12_bin   595212 non-null  int64  \n",
      " 14  ps_ind_13_bin   595212 non-null  int64  \n",
      " 15  ps_ind_14       595212 non-null  int64  \n",
      " 16  ps_ind_15       595212 non-null  int64  \n",
      " 17  ps_ind_16_bin   595212 non-null  int64  \n",
      " 18  ps_ind_17_bin   595212 non-null  int64  \n",
      " 19  ps_ind_18_bin   595212 non-null  int64  \n",
      " 20  ps_reg_01       595212 non-null  float64\n",
      " 21  ps_reg_02       595212 non-null  float64\n",
      " 22  ps_reg_03       595212 non-null  float64\n",
      " 23  ps_car_01_cat   595212 non-null  int64  \n",
      " 24  ps_car_02_cat   595212 non-null  int64  \n",
      " 25  ps_car_03_cat   595212 non-null  int64  \n",
      " 26  ps_car_04_cat   595212 non-null  int64  \n",
      " 27  ps_car_05_cat   595212 non-null  int64  \n",
      " 28  ps_car_06_cat   595212 non-null  int64  \n",
      " 29  ps_car_07_cat   595212 non-null  int64  \n",
      " 30  ps_car_08_cat   595212 non-null  int64  \n",
      " 31  ps_car_09_cat   595212 non-null  int64  \n",
      " 32  ps_car_10_cat   595212 non-null  int64  \n",
      " 33  ps_car_11_cat   595212 non-null  int64  \n",
      " 34  ps_car_11       595212 non-null  int64  \n",
      " 35  ps_car_12       595212 non-null  float64\n",
      " 36  ps_car_13       595212 non-null  float64\n",
      " 37  ps_car_14       595212 non-null  float64\n",
      " 38  ps_car_15       595212 non-null  float64\n",
      " 39  ps_calc_01      595212 non-null  float64\n",
      " 40  ps_calc_02      595212 non-null  float64\n",
      " 41  ps_calc_03      595212 non-null  float64\n",
      " 42  ps_calc_04      595212 non-null  int64  \n",
      " 43  ps_calc_05      595212 non-null  int64  \n",
      " 44  ps_calc_06      595212 non-null  int64  \n",
      " 45  ps_calc_07      595212 non-null  int64  \n",
      " 46  ps_calc_08      595212 non-null  int64  \n",
      " 47  ps_calc_09      595212 non-null  int64  \n",
      " 48  ps_calc_10      595212 non-null  int64  \n",
      " 49  ps_calc_11      595212 non-null  int64  \n",
      " 50  ps_calc_12      595212 non-null  int64  \n",
      " 51  ps_calc_13      595212 non-null  int64  \n",
      " 52  ps_calc_14      595212 non-null  int64  \n",
      " 53  ps_calc_15_bin  595212 non-null  int64  \n",
      " 54  ps_calc_16_bin  595212 non-null  int64  \n",
      " 55  ps_calc_17_bin  595212 non-null  int64  \n",
      " 56  ps_calc_18_bin  595212 non-null  int64  \n",
      " 57  ps_calc_19_bin  595212 non-null  int64  \n",
      " 58  ps_calc_20_bin  595212 non-null  int64  \n",
      "dtypes: float64(10), int64(49)\n",
      "memory usage: 267.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"D:\\data science\\capstone project\\587_cap_proj_dataset_v1.0\\train(1).csv\")\n",
    "\n",
    "# Display basic statistics and information\n",
    "print(df.describe())\n",
    "print(df.info())\n",
    "\n",
    "# Handling missing values\n",
    "df_filled = df.fillna(df.mean())  # Filling missing values with mean\n",
    "\n",
    "# Feature Scaling/Normalization\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_filled), columns=df_filled.columns)\n",
    "\n",
    "# Extracting features and target\n",
    "features = df_scaled.drop(columns=['target'])  # Assuming 'target' is the column to predict\n",
    "target = df_scaled['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_distribution = df['target'].value_counts(normalize=True)\n",
    "print(target_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "print(f'Categorical Features: {len(categorical_features)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_values.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_with_missing = missing_values[missing_values > 0].count()\n",
    "print(f'Total Features with Missing Values: {num_features_with_missing}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['ord_feature1', 'ord_feature2']\n",
    "ord_correlation = df[ordinal_features].corr()\n",
    "print(ord_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_after_encoding = df_encoded.shape[1]\n",
    "print(f'Number of Features after Encoding: {num_features_after_encoding}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model  # Choose based on metrics like recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement with Ensemble Methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
